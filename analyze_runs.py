#!/usr/bin/env python3
"""
Analyze Neptune run distribution to determine optimal export time ranges.
Usage: uv run python analyze_runs.py <project-id> <num-jobs> [output-file]
Example: uv run python analyze_runs.py si-inc/molmo 4
Example: uv run python analyze_runs.py si-inc/molmo 4 export-config.sh
"""

import os
import sys
from datetime import datetime
import neptune_query as nq
from neptune_query import filters, runs as nq_runs
from neptune_query.filters import Attribute, AttributeFilter


def analyze_run_distribution(project_id: str, num_jobs: int, output_file: str = None):
    """Analyze run creation times and suggest optimal date ranges for parallel export."""

    api_token = os.getenv("NEPTUNE_API_TOKEN")
    if not api_token:
        print("Error: NEPTUNE_API_TOKEN not set")
        sys.exit(1)

    # Set the API token
    nq.set_api_token(api_token)

    print(f"Fetching runs from {project_id}...")

    # List all runs
    runs_filter = filters.Filter.matches(
        filters.Attribute("sys/custom_run_id", type="string"), ".+"
    )
    run_ids = nq_runs.list_runs(project=project_id, runs=runs_filter)

    print(f"Found {len(run_ids)} runs. Fetching creation times...")

    # Fetch sys/creation_time for all runs
    runs_df = nq_runs.fetch_runs_table(
        project=project_id,
        runs=run_ids,
        attributes=AttributeFilter(name=["sys/creation_time"], type=["datetime"]),
        sort_by=Attribute(name="sys/creation_time", type="datetime"),
        sort_direction="asc",
    )

    if runs_df.empty:
        print("DataFrame is empty")
        return

    # Try to find the creation time column
    creation_col = None
    for col in runs_df.columns:
        if "creation" in col.lower():
            creation_col = col
            break

    if creation_col is None:
        print("No creation_time column found. Available columns:")
        for col in runs_df.columns:
            print(f"  - {col}")
        return

    # Extract creation times and sort
    creation_times = runs_df[creation_col].dropna().sort_values().tolist()

    if not creation_times:
        print("No runs found or no creation times available")
        return

    creation_times.sort()
    total_runs = len(creation_times)
    runs_per_job = total_runs // num_jobs

    print(f"\nTotal runs: {total_runs}")
    print(f"Target runs per job: {runs_per_job}")

    # Calculate date ranges
    date_ranges = []
    for i in range(num_jobs):
        start_idx = i * runs_per_job
        # Last job gets any remaining runs
        end_idx = (i + 1) * runs_per_job if i < num_jobs - 1 else total_runs

        start_date = creation_times[start_idx].strftime("%Y-%m-%d")
        end_date = creation_times[end_idx - 1].strftime("%Y-%m-%d")
        num_runs = end_idx - start_idx
        date_ranges.append((start_date, end_date, num_runs))

    # Calculate average interval (for reference only)
    from datetime import datetime
    total_days = (datetime.strptime(date_ranges[-1][1], "%Y-%m-%d") -
                  datetime.strptime(date_ranges[0][0], "%Y-%m-%d")).days
    avg_interval = total_days // num_jobs if num_jobs > 0 else 0

    # Generate config content
    config_content = f"""#!/bin/bash
# Auto-generated by analyze_runs.py
# Project: {project_id}
# Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

USE_OPTIMAL_RANGES=true
PARALLEL_JOBS={num_jobs}
START_DATES=({' '.join(f'"{sd}"' for sd, _, _ in date_ranges)})
END_DATES=({' '.join(f'"{ed}"' for _, ed, _ in date_ranges)})

# For reference:
START_DATE="{date_ranges[0][0]}"
END_DATE="{date_ranges[-1][1]}"
INTERVAL_DAYS={avg_interval}  # Average only
"""

    # Write to file if specified
    if output_file:
        with open(output_file, 'w') as f:
            f.write(config_content)
        print(f"âœ“ Config written to: {output_file}")
        print(f"\nTo use this config, run:")
        print(f"  ./parallel-neptune-export.sh {project_id} {output_file}")
        print()

    # Print configuration
    print(f"\n{'='*60}")
    print(f"Configuration for parallel-neptune-export.sh")
    print(f"{'='*60}\n")
    print(config_content)

    # Print summary
    print(f"{'='*60}")
    print(f"Job Distribution Summary")
    print(f"{'='*60}")
    print(f"Total runs: {total_runs}")
    print(f"Total days: {total_days}")
    print()
    for i, (start_date, end_date, num_runs) in enumerate(date_ranges, 1):
        days = (datetime.strptime(end_date, "%Y-%m-%d") -
                datetime.strptime(start_date, "%Y-%m-%d")).days + 1
        print(f"Job {i}: {start_date} to {end_date} - {num_runs:3d} runs, {days:3d} days")
    print()


if __name__ == "__main__":
    if len(sys.argv) < 3 or len(sys.argv) > 4:
        print("Usage: uv run python analyze_runs.py <project-id> <num-jobs> [output-file]")
        print("Example: uv run python analyze_runs.py si-inc/molmo 4")
        print("Example: uv run python analyze_runs.py si-inc/molmo 4 export-config.sh")
        sys.exit(1)

    project_id = sys.argv[1]
    num_jobs = int(sys.argv[2])
    output_file = sys.argv[3] if len(sys.argv) == 4 else None

    analyze_run_distribution(project_id, num_jobs, output_file)
